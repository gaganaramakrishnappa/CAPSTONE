{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "dataset = pd.read_csv('final.csv')\n",
    "dataset = dataset.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipaddress\n",
    "import urllib\n",
    "import urllib.request\n",
    "from urllib.parse import urlparse\n",
    "from bs4 import BeautifulSoup\n",
    "from tldextract import extract\n",
    "from whois import whois\n",
    "import regex\n",
    "import ssl\n",
    "import socket\n",
    "import requests\n",
    "import re\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1\n",
      "-1\n"
     ]
    }
   ],
   "source": [
    "def url_ip(url):\n",
    "    try:\n",
    "        a=re.match('(^(http|https):){0,1}(//){0,1}[a-z0-9]*(/){0,1}\\d+\\.\\d+\\.\\d+\\.\\d+\\.*',url)\n",
    "        if a is None:\n",
    "            return -1\n",
    "        else:\n",
    "            return 1\n",
    "    except:\n",
    "        ip=-1\n",
    "    try:\n",
    "        ipaddress.ip_address(a)\n",
    "        ip=1\n",
    "    except:\n",
    "        ip=-1\n",
    "    return ip\n",
    "r=url_ip('google.com')\n",
    "print(r)\n",
    "r1=url_ip('officeon.ch.ma/office.js?google_ad_format=728x90_as')\n",
    "print(r1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1\n",
      "-1\n"
     ]
    }
   ],
   "source": [
    "def getLength(url):\n",
    "    length=len(url)\n",
    "    if(length<54):\n",
    "        return -1\n",
    "    elif(54<=length<=75):\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "\n",
    "r=getLength('google.com')\n",
    "print(r)\n",
    "r1=getLength('officeon.ch.ma/office.js?google_ad_format=728x90_as')\n",
    "print(r1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1\n",
      "-1\n"
     ]
    }
   ],
   "source": [
    "def tinyURL(url):\n",
    "    shortening_services = r\"bit\\.ly|goo\\.gl|shorte\\.st|go2l\\.ink|x\\.co|ow\\.ly|t\\.co|tinyurl|tr\\.im|is\\.gd|cli\\.gs|\" \\\n",
    "                          r\"yfrog\\.com|migre\\.me|ff\\.im|tiny\\.cc|url4\\.eu|twit\\.ac|su\\.pr|twurl\\.nl|snipurl\\.com|\" \\\n",
    "                          r\"short\\.to|BudURL\\.com|ping\\.fm|post\\.ly|Just\\.as|bkite\\.com|snipr\\.com|fic\\.kr|loopt\\.us|\" \\\n",
    "                          r\"doiop\\.com|short\\.ie|kl\\.am|wp\\.me|rubyurl\\.com|om\\.ly|to\\.ly|bit\\.do|t\\.co|lnkd\\.in|db\\.tt|\" \\\n",
    "                          r\"qr\\.ae|adf\\.ly|goo\\.gl|bitly\\.com|cur\\.lv|tinyurl\\.com|ow\\.ly|bit\\.ly|ity\\.im|q\\.gs|is\\.gd|\" \\\n",
    "                          r\"po\\.st|bc\\.vc|twitthis\\.com|u\\.to|j\\.mp|buzurl\\.com|cutt\\.us|u\\.bb|yourls\\.org|x\\.co|\" \\\n",
    "                          r\"prettylinkpro\\.com|scrnch\\.me|filoops\\.info|vzturl\\.com|qr\\.net|1url\\.com|tweez\\.me|v\\.gd|\" \\\n",
    "                          r\"tr\\.im|link\\.zip\\.net\"\n",
    "    match = re.search(shortening_services, url)\n",
    "    if match:\n",
    "        return 1\n",
    "    else:\n",
    "        return -1\n",
    "r=tinyURL('google.com')\n",
    "print(r)\n",
    "r1=tinyURL('officeon.ch.ma/office.js?google_ad_format=728x90_as')\n",
    "print(r1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1\n",
      "-1\n"
     ]
    }
   ],
   "source": [
    "def at_the_rate_count(url):\n",
    "    symbol=regex.findall(r'@',url)\n",
    "    if(len(symbol)==0):\n",
    "        return -1\n",
    "    else:\n",
    "        return 1 \n",
    "\n",
    "'''def at_the_rate_count(url):\n",
    "    count = url.count(\"@\")\n",
    "    if count > 0:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0'''\n",
    "r=at_the_rate_count('google.com')\n",
    "print(r)\n",
    "r1=at_the_rate_count('officeon.ch.ma/office.js?google_ad_format=728x90_as')\n",
    "print(r1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "def redirection(url):\n",
    "    if 'http' not in url and 'https' not in url:\n",
    "        url='http://'+url\n",
    "    pos = url.rfind('//')\n",
    "    if pos > 6:\n",
    "        if pos > 7:\n",
    "            return 1\n",
    "        else:\n",
    "            return -1\n",
    "    else:\n",
    "        return -1\n",
    "r=redirection('google.com')\n",
    "print(r)\n",
    "r1=redirection('www.asd//officeon.ch.maoffice.js?google_ad_format=728x90_as')\n",
    "print(r1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "def prefixSuffix(url):\n",
    "    if 'http' not in url and 'https' not in url:\n",
    "        url='http://'+url\n",
    "    if '-' in urlparse(url).netloc:\n",
    "        return 1  \n",
    "    else:\n",
    "        return -1\n",
    "r=prefixSuffix('google.com')\n",
    "print(r)\n",
    "r1=prefixSuffix('www.offi-ceon.ch.ma/office.js?google_ad_format=728x90_as')\n",
    "print(r1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "www\n",
      "-1\n",
      "www.officeon\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "def sub_domain(url):\n",
    "    subDomain, domain, suffix = extract(url)\n",
    "    print(subDomain)\n",
    "    if (subDomain.count('.') == 1):\n",
    "        return 0\n",
    "    elif (subDomain.count(\".\") == 2):\n",
    "        return 1\n",
    "    else:\n",
    "        return -1\n",
    "r=sub_domain('www.google.com')\n",
    "print(r)\n",
    "r1=sub_domain('www.officeon.ch.ma/office.js?google_ad_format=728x90_as')\n",
    "print(r1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "def http_domain(url):\n",
    "    domain = url.split(':')\n",
    "    if 'https' in domain:\n",
    "        return -1\n",
    "    else:\n",
    "        return 1\n",
    "r=http_domain('https://google.com')\n",
    "print(r)\n",
    "r1=http_domain('officeon.ch.ma/office.js?google_ad_format=728x90_as')\n",
    "print(r1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1\n",
      "-1\n"
     ]
    }
   ],
   "source": [
    "def domain_registration(url):\n",
    "    try:\n",
    "        w = whois.whois(url)\n",
    "        updated = w.updated_date\n",
    "        exp = w.expiration_date\n",
    "        length = (exp[0]-updated[0]).days\n",
    "        if(length<=365):\n",
    "            return 1\n",
    "        else:\n",
    "            return -1\n",
    "    except:\n",
    "        return -1\n",
    "    \n",
    "r=domain_registration('google.com')\n",
    "print(r)\n",
    "r1=domain_registration('officeon.ch.ma/office.js?google_ad_format=728x90_as')\n",
    "print(r1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "def age_of_domain(url):\n",
    "    try:\n",
    "        w = whois(url)\n",
    "        start_date = w.creation_date\n",
    "        current_date = datetime.datetime.now()\n",
    "        age =(current_date-start_date[0]).days\n",
    "        if(age>=180): \n",
    "            return -1\n",
    "        else:\n",
    "            return 1\n",
    "    except Exception as e:\n",
    "        return 0\n",
    "    \n",
    "    \n",
    "r=age_of_domain('google.com')\n",
    "print(r)\n",
    "r1=age_of_domain('http://officeon.ch.ma/office.js?google_ad_format=728x90_as')\n",
    "print(r1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "def web_traffic(url):\n",
    "    try:\n",
    "        url = urllib.parse.quote(url)\n",
    "        rank = BeautifulSoup(urllib.request.urlopen(\"http://data.alexa.com/data?cli=10&dat=s&url=\" + url).read(), \"xml\").find(\"REACH\")['RANK']\n",
    "   \n",
    "    except TypeError:\n",
    "        return 0\n",
    "    rank=int(rank)\n",
    "    \n",
    "    if rank < 100000:\n",
    "        return -1\n",
    "    elif rank == 100000:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "    \n",
    "r=web_traffic('google.com')\n",
    "print(r)\n",
    "r1=web_traffic('officeon.ch.ma/office.js?google_ad_format=728x90_as')\n",
    "print(r1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "def numberoflinks(url):      \n",
    "    if 'http' not in url and 'https' not in url:\n",
    "        url='http://'+url\n",
    "    try: \n",
    "        response = requests.get(url)\n",
    "    except:\n",
    "        response = \"\"\n",
    "    try:\n",
    "        number_of_links = len(re.findall(r\"<a href=\", response.text)) \n",
    "        if number_of_links == 0:         \n",
    "            return 1    \n",
    "        elif number_of_links>0 and number_of_links<=2:\n",
    "            return 0\n",
    "        else:\n",
    "            return -1\n",
    "    except:\n",
    "        return 0\n",
    "r=numberoflinks('google.com')\n",
    "print(r)\n",
    "r1=numberoflinks('www.officeon.ch.ma/office.js?google_ad_format=728x90_as')\n",
    "print(r1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1\n",
      "-1\n"
     ]
    }
   ],
   "source": [
    "def forwarding(url):\n",
    "    if 'http' not in url and 'https' not in url:\n",
    "        url='http://'+url\n",
    "    try: \n",
    "        response = requests.get(url)\n",
    "    except:\n",
    "        response = \"\"\n",
    "    if response == \"\":\n",
    "        return 1\n",
    "    else:\n",
    "        if len(response.history) <=1:\n",
    "            return -1\n",
    "        elif (len(response.history)>=2 and len(response.history)<4):\n",
    "            return 0\n",
    "        else:\n",
    "            return 1\n",
    "r=forwarding('google.com')\n",
    "print(r)\n",
    "r1=forwarding('www.officeon.ch.ma/office.js?google_ad_format=728x90_as')\n",
    "print(r1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1\n",
      "-1\n"
     ]
    }
   ],
   "source": [
    "def mouseOver(url):\n",
    "    if 'http' not in url and 'https' not in url:\n",
    "        url='http://'+url\n",
    "    try: \n",
    "        response = requests.get(url)\n",
    "    except:\n",
    "        response = \"\"\n",
    "    if response == \"\" :\n",
    "        return 1\n",
    "    else:\n",
    "        if re.findall(\"<script>.+onmouseover.+</script>\", response.text):\n",
    "            return 1\n",
    "        else:\n",
    "            return -1\n",
    "\n",
    "r=mouseOver('google.com')\n",
    "print(r)\n",
    "r1=mouseOver('officeon.ch.ma/office.js?google_ad_format=728x90_as')\n",
    "print(r1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1\n",
      "-1\n"
     ]
    }
   ],
   "source": [
    "def rightClick(url):\n",
    "    if 'http' not in url and 'https' not in url:\n",
    "        url='http://'+url\n",
    "    try: \n",
    "        response = requests.get(url)\n",
    "    except:\n",
    "        response = \"\"\n",
    "    if response == \"\":\n",
    "        return 1\n",
    "    else:\n",
    "        if re.findall(r\"event.button ?== ?2\", response.text):\n",
    "            return 1\n",
    "        else:\n",
    "            return -1\n",
    "r=rightClick('google.com')\n",
    "print(r)\n",
    "r1=rightClick('officeon.ch.ma/office.js?google_ad_format=728x90_as')\n",
    "print(r1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1\n",
      "-1\n"
     ]
    }
   ],
   "source": [
    "def iframe(url):\n",
    "    if 'http' not in url and 'https' not in url:\n",
    "        url='http://'+url\n",
    "    try: \n",
    "        response = requests.get(url)\n",
    "    except:\n",
    "        response = \"\"\n",
    "    if response == \"\":\n",
    "        return 1\n",
    "    else:\n",
    "        if '<iframe>' in response.text or '<frameBorder>' in response.text:\n",
    "            return 1\n",
    "        else:\n",
    "            return -1\n",
    "r=iframe('google.com')\n",
    "print(r)\n",
    "r1=iframe('officeon.ch.ma/office.js?google_ad_format=728x90_as')\n",
    "print(r1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "def request_url(url):\n",
    "    if 'http' not in url and 'https' not in url:\n",
    "        url='http://'+url\n",
    "    try:\n",
    "        subDomain, domain, suffix = extract(url)\n",
    "        websiteDomain = domain\n",
    "        opener = urllib.request.urlopen(url).read()\n",
    "        soup = BeautifulSoup(opener, 'lxml')\n",
    "        imgs = soup.findAll('img', src=True)\n",
    "        total = len(imgs)\n",
    "        linked_to_same = 0\n",
    "        avg = 0\n",
    "        for image in imgs:\n",
    "            subDomain, domain, suffix = extract(image['src'])\n",
    "            imageDomain = domain\n",
    "            if (websiteDomain == imageDomain or imageDomain == ''):\n",
    "                linked_to_same = linked_to_same + 1\n",
    "        vids = soup.findAll('video', src=True)\n",
    "        total = total + len(vids)\n",
    "        for video in vids:\n",
    "            subDomain, domain, suffix = extract(video['src'])\n",
    "            vidDomain = domain\n",
    "            if (websiteDomain == vidDomain or vidDomain == ''):\n",
    "                linked_to_same = linked_to_same + 1\n",
    "        linked_outside = total - linked_to_same\n",
    "        if (total != 0):\n",
    "            avg = linked_outside / total\n",
    "        if(avg<0.22):\n",
    "            return -1\n",
    "        elif(0.22<=avg<=0.61):\n",
    "            return 0\n",
    "        else:\n",
    "            return 1\n",
    "    except:\n",
    "        return 0\n",
    "r=request_url('google.com')\n",
    "print(r)\n",
    "r1=request_url('officeon.ch.ma/office.js?google_ad_format=728x90_as')\n",
    "print(r1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "def url_of_anchor(url):\n",
    "    if 'http' not in url and 'https' not in url:\n",
    "        url='http://'+url\n",
    "    try:\n",
    "        subDomain, domain, suffix = extract(url)\n",
    "        websiteDomain = domain\n",
    "        opener = urllib.request.urlopen(url).read()\n",
    "        soup = BeautifulSoup(opener, 'lxml')\n",
    "        anchors = soup.findAll('a', href=True)\n",
    "        total = len(anchors)\n",
    "        linked_to_same = 0\n",
    "        avg = 0\n",
    "        for anchor in anchors:\n",
    "            subDomain, domain, suffix = extract(anchor['href'])\n",
    "            anchorDomain = domain\n",
    "            if (websiteDomain == anchorDomain or anchorDomain == ''):\n",
    "                linked_to_same = linked_to_same + 1\n",
    "        linked_outside = total - linked_to_same\n",
    "        if (total != 0):\n",
    "            avg = linked_outside / total\n",
    "        if (avg < 0.31):\n",
    "            return -1\n",
    "        elif avg>=0.31 and avg<=0.67:\n",
    "            return 0\n",
    "        else:\n",
    "            return 1\n",
    "    except:\n",
    "        return 0\n",
    "r=url_of_anchor('google.com')\n",
    "print(r)\n",
    "r1=url_of_anchor('officeon.ch.ma/office.js?google_ad_format=728x90_as')\n",
    "print(r1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "def Links_in_tags(url):\n",
    "    if 'http' not in url and 'https' not in url:\n",
    "        url='http://'+url\n",
    "    try:\n",
    "        opener = urllib.request.urlopen(url).read()\n",
    "        soup = BeautifulSoup(opener, 'lxml')\n",
    "        no_of_meta = 0\n",
    "        no_of_link = 0\n",
    "        no_of_script = 0\n",
    "        anchors = 0\n",
    "        avg = 0\n",
    "        for meta in soup.find_all('meta'):\n",
    "            no_of_meta = no_of_meta + 1\n",
    "        for link in soup.find_all('link'):\n",
    "            no_of_link = no_of_link + 1\n",
    "        for script in soup.find_all('script'):\n",
    "            no_of_script = no_of_script + 1\n",
    "        for anchor in soup.find_all('a'):\n",
    "            anchors = anchors + 1\n",
    "        total = no_of_meta + no_of_link + no_of_script + anchors\n",
    "        tags = no_of_meta + no_of_link + no_of_script\n",
    "        if (total != 0):\n",
    "            avg = tags / total\n",
    "        if(avg<0.25):\n",
    "            return -1\n",
    "        elif(0.25<=avg<=0.81):\n",
    "            return 0\n",
    "        else:\n",
    "            return 1        \n",
    "    except:        \n",
    "        return 0\n",
    "r=Links_in_tags('google.com')\n",
    "print(r)\n",
    "r1=Links_in_tags('officeon.ch.ma/office.js?google_ad_format=728x90_as')\n",
    "print(r1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1\n",
      "-1\n"
     ]
    }
   ],
   "source": [
    "def email_submit(url):\n",
    "    if 'http' not in url and 'https' not in url:\n",
    "        url='http://'+url\n",
    "    try:\n",
    "        opener = urllib.request.urlopen(url).read()\n",
    "        soup = BeautifulSoup(opener, 'lxml')\n",
    "        if(soup.find('mailto:')):\n",
    "            return 1\n",
    "        else:\n",
    "            return -1\n",
    "    except:\n",
    "        return 0\n",
    "r=email_submit('google.com')\n",
    "print(r)\n",
    "r1=email_submit('officeon.ch.ma/office.js?google_ad_format=728x90_as')\n",
    "print(r1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1\n",
      "-1\n"
     ]
    }
   ],
   "source": [
    "from urllib.parse import urlparse\n",
    "\n",
    "def abnormal_url(url):\n",
    "    if 'http' not in url and 'https' not in url:\n",
    "        url='http://'+url\n",
    "    domain = urlparse(url).netloc\n",
    "    if url.find(domain)==-1:\n",
    "        return 1\n",
    "    else:\n",
    "        return -1\n",
    "r=abnormal_url('google.com')\n",
    "print(r)\n",
    "r1=abnormal_url('officeon.ch.ma/office.js?google_ad_format=728x90_as')\n",
    "print(r1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "-1\n"
     ]
    }
   ],
   "source": [
    "'''def SSLfinal_State(url):\n",
    "    try:\n",
    "        subDomain, domain, suffix = extract(url)\n",
    "        host_name = domain + \".\" + suffix\n",
    "        context = ssl.create_default_context()\n",
    "        sct = context.wrap_socket(socket.socket(), server_hostname=host_name)\n",
    "        sct.connect((host_name, 443))\n",
    "        certificate = sct.getpeercert()\n",
    "        issuer = dict(x[0] for x in certificate['issuer'])\n",
    "        certificate_Auth = str(issuer['commonName'])\n",
    "        certificate_Auth = certificate_Auth.split()\n",
    "        if certificate_Auth[0] == \"Network\" or certificate_Auth == \"Deutsche\":\n",
    "            certificate_Auth = certificate_Auth[0] + \" \" + certificate_Auth[1]\n",
    "        else:\n",
    "            certificate_Auth = certificate_Auth[0]\n",
    "        trusted_Auth = ['Comodo', 'Symantec', 'GoDaddy', 'GlobalSign', 'DigiCert', 'StartCom', 'Entrust', 'Verizon',\n",
    "                        'Trustwave', 'Unizeto', 'Buypass', 'QuoVadis', 'Deutsche Telekom', 'Network Solutions',\n",
    "                        'SwissSign', 'IdenTrust', 'Secom', 'TWCA', 'GeoTrust', 'Thawte', 'Doster', 'VeriSign','GTS']\n",
    "        startingDate = str(certificate['notBefore'])\n",
    "        endingDate = str(certificate['notAfter'])\n",
    "        startingYear = int(startingDate.split()[3])\n",
    "        endingYear = int(endingDate.split()[3])\n",
    "        Age_of_certificate = endingYear - startingYear\n",
    "\n",
    "        if ( (certificate_Auth in trusted_Auth) and (Age_of_certificate >= 1)):\n",
    "            return 0 \n",
    "\n",
    "        elif ((certificate_Auth not in trusted_Auth)):\n",
    "            return 1  \n",
    "        else:\n",
    "            return 1  \n",
    "\n",
    "    except Exception as e:\n",
    "\n",
    "        return 1'''\n",
    "    \n",
    "\n",
    "def SSLfinal_State(url):\n",
    "    try:\n",
    "#check wheather contains https       \n",
    "        if(regex.search('^https',url)):\n",
    "            usehttps = 1\n",
    "        else:\n",
    "            usehttps = 0\n",
    "#getting the certificate issuer to later compare with trusted issuer \n",
    "        #getting host name\n",
    "        subDomain, domain, suffix = extract(url)\n",
    "        host_name = domain + \".\" + suffix\n",
    "        context = ssl.create_default_context()\n",
    "        sct = context.wrap_socket(socket.socket(), server_hostname = host_name)\n",
    "        sct.connect((host_name, 443))\n",
    "        certificate = sct.getpeercert()\n",
    "        issuer = dict(x[0] for x in certificate['issuer'])\n",
    "        certificate_Auth = str(issuer['commonName'])\n",
    "        certificate_Auth = certificate_Auth.split()\n",
    "        if(certificate_Auth[0] == \"Network\" or certificate_Auth == \"Deutsche\"):\n",
    "            certificate_Auth = certificate_Auth[0] + \" \" + certificate_Auth[1]\n",
    "        else:\n",
    "            certificate_Auth = certificate_Auth[0] \n",
    "        trusted_Auth = ['Comodo','Symantec','GoDaddy','GlobalSign','DigiCert','StartCom','Entrust','Verizon','Trustwave','Unizeto','Buypass','QuoVadis','Deutsche Telekom','Network Solutions','SwissSign','IdenTrust','Secom','TWCA','GeoTrust','Thawte','Doster','VeriSign']        \n",
    "#getting age of certificate\n",
    "        startingDate = str(certificate['notBefore'])\n",
    "        endingDate = str(certificate['notAfter'])\n",
    "        startingYear = int(startingDate.split()[3])\n",
    "        endingYear = int(endingDate.split()[3])\n",
    "        Age_of_certificate = endingYear-startingYear\n",
    "        \n",
    "#checking final conditions\n",
    "        if((usehttps==1) and (certificate_Auth in trusted_Auth) and (Age_of_certificate>=1) ):\n",
    "            return -1 #legitimate\n",
    "        elif((usehttps==1) and (certificate_Auth not in trusted_Auth)):\n",
    "            return 0 #suspicious\n",
    "        else:\n",
    "            return 1 #phishing\n",
    "        \n",
    "    except Exception as e:\n",
    "        \n",
    "        return -1\n",
    "\n",
    "\n",
    "r=SSLfinal_State('google.com')\n",
    "print(r)\n",
    "r1=SSLfinal_State('officeon.ch.ma/office.js?google_ad_format=728x90_as')\n",
    "print(r1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1\n",
      "-1\n"
     ]
    }
   ],
   "source": [
    "def popUpwindow(url):\n",
    "    if 'http' not in url and 'https' not in url:\n",
    "        url='http://'+url\n",
    "    try: \n",
    "        response = requests.get(url)\n",
    "    except:\n",
    "        response = \"\"\n",
    "    try:         \n",
    "        if re.findall(r\"alert\\(\", response.text):            \n",
    "            return 1         \n",
    "        else:             \n",
    "            return -1   \n",
    "    except:\n",
    "        return -1\n",
    "r=popUpwindow('google.com')\n",
    "print(r)\n",
    "r1=popUpwindow('www.officeon.ch.ma/office.js?google_ad_format=728x90_as')\n",
    "print(r1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Url_having_ip = []\n",
    "Get_length=[]\n",
    "Tiny_url = []\n",
    "At_the_rate_count=[]\n",
    "Redirection=[]\n",
    "Prefix_suffix = []\n",
    "Sub_domain=[]\n",
    "Age_of_domain=[]\n",
    "Web_traffic=[]\n",
    "Iframe=[]\n",
    "Mouse_over=[]\n",
    "Right_click=[]\n",
    "Forwarding=[]\n",
    "Http_domain=[]\n",
    "Domain_registration=[]\n",
    "Ssl_final_state=[]\n",
    "Request_url=[]\n",
    "Url_of_anchor=[]\n",
    "Links_in_Tags=[]\n",
    "Email_submit=[]\n",
    "Abnormal_url=[]\n",
    "pop_up_window = []\n",
    "no_of_links=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c=1\n",
    "for url in dataset['URL']:\n",
    "    print(url)\n",
    "    Url_having_ip.append(url_ip(url))\n",
    "    Age_of_domain.append(age_of_domain(url))\n",
    "    Web_traffic.append(web_traffic(url))\n",
    "    Get_length.append(getLength(url))\n",
    "    Tiny_url.append(tinyURL(url))\n",
    "    At_the_rate_count.append(at_the_rate_count(url))\n",
    "    Redirection.append(redirection(url))\n",
    "    Prefix_suffix.append(prefixSuffix(url))\n",
    "    Sub_domain.append(sub_domain(url))\n",
    "    Http_domain.append(http_domain(url))\n",
    "    Domain_registration.append(domain_registration(url))\n",
    "    Ssl_final_state.append(SSLfinal_State(url))\n",
    "    Request_url.append(request_url(url))\n",
    "    Url_of_anchor.append(url_of_anchor(url))\n",
    "    Links_in_Tags.append( Links_in_tags(url))\n",
    "    Email_submit.append(email_submit(url))\n",
    "    Abnormal_url.append(abnormal_url(url))\n",
    "    Mouse_over.append(mouseOver(url))\n",
    "    Iframe.append(iframe(url))\n",
    "    Right_click.append(rightClick(url))\n",
    "    Forwarding.append(forwarding(url))\n",
    "    pop_up_window.append(popUpwindow(url))\n",
    "    no_of_links.append(numberoflinks(url))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_df = pd.DataFrame()\n",
    "features_df['url_having_ip'] = Url_having_ip\n",
    "features_df['get_length'] = Get_length\n",
    "features_df['tiny_url']=Tiny_url\n",
    "features_df['at_the_rate_count'] = At_the_rate_count\n",
    "features_df['redirection'] = Redirection\n",
    "features_df['prefix_suffix']=Prefix_suffix\n",
    "features_df['sub_domain'] = Sub_domain\n",
    "features_df['age_of_domain'] = Age_of_domain\n",
    "features_df['web_traffic'] = Web_traffic\n",
    "features_df['iframe'] = Iframe\n",
    "features_df['mouse_over'] = Mouse_over\n",
    "features_df['right_click'] = Right_click\n",
    "features_df['forwarding'] = Forwarding\n",
    "features_df['http_domain'] = Http_domain\n",
    "features_df['domain_registration'] = Domain_registration\n",
    "features_df['ssl_final_state'] = Ssl_final_state\n",
    "features_df['request_url'] = Request_url\n",
    "features_df['url_of_anchor'] = Url_of_anchor\n",
    "features_df['links_in_Tags'] = Links_in_Tags\n",
    "features_df['email_submit'] = Email_submit\n",
    "features_df['abnormal_url'] = Abnormal_url\n",
    "features_df['no_of_links'] = no_of_links\n",
    "features_df['pop_up_window'] = pop_up_window\n",
    "print(features_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_df.to_csv('features3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
